"""
SAM3 Model Downloader for Offline Server
ì˜¨ë¼ì¸ í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ì—¬ SAM3 ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê³ 
ì˜¤í”„ë¼ì¸ ì„œë²„ë¡œ ì´ë™ ê°€ëŠ¥í•œ í˜•íƒœë¡œ íŒ¨í‚¤ì§•
"""

import os
import sys
import shutil
import torch
from pathlib import Path
import json
import time
os.environ["CUDA_PATH"] = "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.6"

import certifi
os.environ['SSL_CERT_FILE'] = certifi.where()


def print_header(text):
    """í—¤ë” ì¶œë ¥"""
    print("\n" + "=" * 70)
    print(f"  {text}")
    print("=" * 70)


def download_sam3_model(output_dir="./models", hf_token=None):
    """
    SAM3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
    
    Args:
        output_dir: ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬
        hf_token: HuggingFace í† í° (í•„ìš”ì‹œ)
    """
    print_header("SAM3 Model Download - Offline Preparation")
    
    # HuggingFace í† í° ì„¤ì •
    if hf_token:
        os.environ["HF_TOKEN"] = hf_token
        print(f"âœ“ HuggingFace í† í° ì„¤ì • ì™„ë£Œ")
    
    # SAM3 import ì‹œë„
    try:
        import sam3
        from sam3 import build_sam3_image_model
        print("âœ“ SAM3 íŒ¨í‚¤ì§€ import ì„±ê³µ")
    except ImportError as e:
        print("âœ— SAM3 íŒ¨í‚¤ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print("   ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("   git clone https://github.com/facebookresearch/sam3.git")
        print("   cd sam3 && pip install -e .")
        sys.exit(1)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"âœ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir.absolute()}")
    
    # ========== 1. BPE Vocab íŒŒì¼ ë³µì‚¬ ==========
    print_header("Step 1: BPE Vocab íŒŒì¼ ë³µì‚¬")
    
    sam3_root = Path(sam3.__file__).parent.parent
    bpe_source = sam3_root / "assets" / "bpe_simple_vocab_16e6.txt.gz"
    bpe_target = output_dir / "bpe_simple_vocab_16e6.txt.gz"
    
    if bpe_source.exists():
        shutil.copy2(bpe_source, bpe_target)
        print(f"âœ“ BPE Vocab ë³µì‚¬ ì™„ë£Œ")
        print(f"  From: {bpe_source}")
        print(f"  To:   {bpe_target}")
    else:
        print(f"âš  BPE Vocab íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {bpe_source}")
        print("  ìˆ˜ë™ìœ¼ë¡œ ë³µì‚¬í•´ì£¼ì„¸ìš”.")
    
    # ========== 2. SAM3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ==========
    print_header("Step 2: SAM3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ")
    
    print("ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    print("HuggingFaceì—ì„œ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤.\n")
    
    start_time = time.time()
    
    try:
        # ëª¨ë¸ ë¹Œë“œ (ìë™ ë‹¤ìš´ë¡œë“œ)
        model = build_sam3_image_model(bpe_path=str(bpe_target))
        
        download_time = time.time() - start_time
        print(f"âœ“ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ({download_time:.2f}ì´ˆ)")
        
    except Exception as e:
        print(f"âœ— ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("\nê°€ëŠ¥í•œ ì›ì¸:")
        print("  1. ì¸í„°ë„· ì—°ê²° ë¬¸ì œ")
        print("  2. HuggingFace í† í° í•„ìš”")
        print("  3. ì €ì¥ ê³µê°„ ë¶€ì¡±")
        sys.exit(1)
    
    # ========== 3. ëª¨ë¸ State Dict ì €ì¥ ==========
    print_header("Step 3: ëª¨ë¸ State Dict ì €ì¥")
    
    checkpoint_path = output_dir / "sam3_checkpoint.pth"
    
    try:
        # State dict ì €ì¥
        torch.save(model.state_dict(), checkpoint_path)
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = checkpoint_path.stat().st_size / (1024**3)  # GB
        print(f"âœ“ Checkpoint ì €ì¥ ì™„ë£Œ")
        print(f"  ê²½ë¡œ: {checkpoint_path}")
        print(f"  í¬ê¸°: {file_size:.2f} GB")
        
    except Exception as e:
        print(f"âœ— Checkpoint ì €ì¥ ì‹¤íŒ¨: {e}")
        sys.exit(1)
    
    # ========== 4. HuggingFace ìºì‹œ ì°¾ê¸° ==========
    print_header("Step 4: HuggingFace ìºì‹œ ë¶„ì„")
    
    # HF ìºì‹œ ë””ë ‰í† ë¦¬
    hf_home = Path(os.environ.get('HF_HOME', Path.home() / '.cache' / 'huggingface'))
    hub_cache = hf_home / 'hub'
    
    print(f"HuggingFace ìºì‹œ ìœ„ì¹˜: {hub_cache}")
    
    if hub_cache.exists():
        # SAM3 ê´€ë ¨ ìºì‹œ ì°¾ê¸°
        sam3_models = list(hub_cache.glob("models--*sam3*"))
        
        if sam3_models:
            print(f"âœ“ SAM3 ìºì‹œ ë°œê²¬: {len(sam3_models)}ê°œ")
            
            for model_cache in sam3_models:
                print(f"\n  ğŸ“ {model_cache.name}")
                
                # snapshots í´ë”ì—ì„œ ì‹¤ì œ íŒŒì¼ ì°¾ê¸°
                snapshots = model_cache / "snapshots"
                if snapshots.exists():
                    for snapshot in snapshots.iterdir():
                        if snapshot.is_dir():
                            files = list(snapshot.iterdir())
                            print(f"     â””â”€ {snapshot.name[:12]}... ({len(files)} files)")
                            
                            # ì£¼ìš” íŒŒì¼ í‘œì‹œ
                            for f in files[:5]:  # ìµœëŒ€ 5ê°œë§Œ
                                size_mb = f.stat().st_size / (1024**2)
                                print(f"        - {f.name} ({size_mb:.1f} MB)")
                            
                            if len(files) > 5:
                                print(f"        ... and {len(files)-5} more files")
        else:
            print("âš  SAM3 ìºì‹œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("  ëª¨ë¸ì´ ë‹¤ë¥¸ ìœ„ì¹˜ì— ë‹¤ìš´ë¡œë“œë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        print(f"âš  HuggingFace ìºì‹œ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {hub_cache}")
    
    # ========== 5. Config íŒŒì¼ ìƒì„± ==========
    print_header("Step 5: Config íŒŒì¼ ìƒì„±")
    
    config = {
        "model_type": "sam3",
        "architecture": "SAM3 Image Model",
        "checkpoint_file": "sam3_checkpoint.pth",
        "bpe_vocab_file": "bpe_simple_vocab_16e6.txt.gz",
        "download_date": time.strftime("%Y-%m-%d %H:%M:%S"),
        "pytorch_version": torch.__version__,
        "cuda_available": torch.cuda.is_available(),
    }
    
    if torch.cuda.is_available():
        config["cuda_version"] = torch.version.cuda
        config["gpu_name"] = torch.cuda.get_device_name(0)
    
    config_path = output_dir / "config.json"
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=2, ensure_ascii=False)
    
    print(f"âœ“ Config íŒŒì¼ ìƒì„±: {config_path}")
    
    # ========== 6. README ìƒì„± ==========
    print_header("Step 6: README ìƒì„±")
    
    readme_content = f"""# SAM3 Model Package for Offline Server

## ğŸ“¦ í¬í•¨ëœ íŒŒì¼

- `sam3_checkpoint.pth` - SAM3 ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ({file_size:.2f} GB)
- `bpe_simple_vocab_16e6.txt.gz` - BPE Vocabulary
- `config.json` - ëª¨ë¸ ì„¤ì • ì •ë³´
- `README.md` - ì´ íŒŒì¼

## ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì •ë³´

- ë‹¤ìš´ë¡œë“œ ë‚ ì§œ: {time.strftime("%Y-%m-%d %H:%M:%S")}
- PyTorch ë²„ì „: {torch.__version__}
- CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}

## ğŸš€ ì˜¤í”„ë¼ì¸ ì„œë²„ì—ì„œ ì‚¬ìš© ë°©ë²•

### 1. íŒŒì¼ ë³µì‚¬
```bash
# ì´ í´ë”ë¥¼ ì„œë²„ë¡œ ë³µì‚¬
scp -r models/ user@server:/path/to/project/
```

### 2. ì½”ë“œì—ì„œ ë¡œë“œ
```python
from sam3 import build_sam3_image_model
import torch

# ë¡œì»¬ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
model = build_sam3_image_model(
    bpe_path="/path/to/models/bpe_simple_vocab_16e6.txt.gz"
)
model.load_state_dict(torch.load("/path/to/models/sam3_checkpoint.pth"))
model.eval()
model = model.cuda()
```

### 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ì˜¤í”„ë¼ì¸ ëª¨ë“œ)
```bash
export HF_DATASETS_OFFLINE=1
export TRANSFORMERS_OFFLINE=1
export HF_HUB_OFFLINE=1
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ì„œë²„ í™˜ê²½ í™•ì¸**
   - PyTorch ë²„ì „ ì¼ì¹˜ í•„ìš”
   - CUDA ë²„ì „ í˜¸í™˜ì„± í™•ì¸
   - GPU ë©”ëª¨ë¦¬ ì¶©ë¶„ (ìµœì†Œ 16GB ê¶Œì¥)

2. **ì˜ì¡´ì„± íŒ¨í‚¤ì§€**
   - requirements.txt ì°¸ì¡°
   - sam3 íŒ¨í‚¤ì§€ ì„¤ì¹˜ í•„ìš”

3. **íŒŒì¼ í¬ê¸°**
   - ì „ì²´ ì•½ {file_size:.2f} GB
   - ë„¤íŠ¸ì›Œí¬ ì „ì†¡ ì‹œê°„ ê³ ë ¤

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨
```python
# ë°©ë²• 1: ì²´í¬í¬ì¸íŠ¸ ì§ì ‘ ë¡œë“œ
state_dict = torch.load("sam3_checkpoint.pth", map_location='cpu')
model.load_state_dict(state_dict)

# ë°©ë²• 2: strict=Falseë¡œ ì‹œë„
model.load_state_dict(state_dict, strict=False)
```

### CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# Mixed precision ì‚¬ìš©
with torch.autocast("cuda", dtype=torch.bfloat16):
    output = model(batch)
```

## ğŸ“ ë¬¸ì˜

ë¬¸ì œ ë°œìƒ ì‹œ config.jsonì˜ ì •ë³´ì™€ í•¨ê»˜ ë¬¸ì˜í•˜ì„¸ìš”.
"""
    
    readme_path = output_dir / "README.md"
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print(f"âœ“ README ìƒì„±: {readme_path}")
    
    # ========== 7. ìµœì¢… ìš”ì•½ ==========
    print_header("ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
    
    print("\nğŸ“¦ ìƒì„±ëœ íŒŒì¼:")
    for file in output_dir.iterdir():
        if file.is_file():
            size = file.stat().st_size
            if size > 1024**3:  # GB
                size_str = f"{size/(1024**3):.2f} GB"
            elif size > 1024**2:  # MB
                size_str = f"{size/(1024**2):.2f} MB"
            else:  # KB
                size_str = f"{size/1024:.2f} KB"
            
            print(f"  âœ“ {file.name} ({size_str})")
    
    print(f"\nğŸ“ ì „ì²´ ì €ì¥ ìœ„ì¹˜: {output_dir.absolute()}")
    
    print("\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
    print("  1. models/ í´ë”ë¥¼ ì„œë²„ë¡œ ë³µì‚¬")
    print("  2. ì„œë²„ì—ì„œ sam3_offline.py ì‹¤í–‰")
    print("  3. GPUë³„ë¡œ run_multi_gpu.shë¡œ ë¶„ì‚° ì‹¤í–‰")
    
    print("\n" + "=" * 70)
    print("  ì¤€ë¹„ ì™„ë£Œ! ì„œë²„ë¡œ ì´ë™í•˜ì„¸ìš”.")
    print("=" * 70 + "\n")
    
    return output_dir


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="SAM3 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì˜¤í”„ë¼ì¸ ì„œë²„ ì¤€ë¹„ìš©)"
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="./models",
        help="ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ (default: ./models)"
    )
    parser.add_argument(
        "--hf_token",
        type=str,
        default=None,
        help="HuggingFace í† í° (í•„ìš”ì‹œ)"
    )
    
    args = parser.parse_args()
    
    try:
        download_sam3_model(
            output_dir=args.output_dir,
            hf_token=args.hf_token
        )
    except KeyboardInterrupt:
        print("\n\nâš  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\n\nâœ— ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
